{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T23:12:06.318123Z",
     "start_time": "2025-06-27T23:12:06.311904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "JSON_FOLDER = 'data_json'\n",
    "CSV_FOLDER = 'data_csv'\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"Input folder: '{JSON_FOLDER}'\")\n",
    "print(f\"Output folder: '{CSV_FOLDER}'\")"
   ],
   "id": "a2b1ab02f271a841",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input folder: 'data_json'\n",
      "Output folder: 'data_csv'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T23:12:10.463078Z",
     "start_time": "2025-06-27T23:12:10.430149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_runs_data = []\n",
    "# Assuming filenames like 'transformer_architecture_scaling_results-1.json'\n",
    "json_files = sorted(glob(os.path.join(JSON_FOLDER, 'transformer_architecture_scaling_results-*.json')))\n",
    "\n",
    "if not json_files:\n",
    "    print(f\"‚ùå ERROR: No JSON files found in '{JSON_FOLDER}'.\")\n",
    "    print(\"Please ensure your files are named 'transformer_architecture_scaling_results-n.json'.\")\n",
    "else:\n",
    "    print(f\"Found {len(json_files)} JSON files to process...\")\n",
    "\n",
    "for i, file_path in enumerate(json_files):\n",
    "    run_id = i + 1\n",
    "    print(f\"\\n--- Processing Run {run_id} ({os.path.basename(file_path)}) ---\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Flatten the new JSON structure\n",
    "    flattened_data = []\n",
    "    for experiment_key, metrics in data.items():\n",
    "        # Use regex to parse the experiment key, e.g., \"decoder_base_n10000\"\n",
    "        match = re.match(r'(\\w+?)_(\\w+?)_n(\\d+)', experiment_key)\n",
    "        if not match:\n",
    "            print(f\"  - Warning: Could not parse key '{experiment_key}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        model_name, size_variant, ds_size = match.groups()\n",
    "\n",
    "        # Get the architecture type from the config dictionary inside the JSON\n",
    "        arch_type = metrics.get('config', {}).get('arch_type', 'unknown')\n",
    "\n",
    "        record = {\n",
    "            'run_id': run_id,\n",
    "            'experiment_key': experiment_key,\n",
    "            'model_name': model_name,\n",
    "            'size_variant': size_variant,\n",
    "            'arch_type': arch_type,\n",
    "            'dataset_size': int(ds_size),\n",
    "            'n_params': metrics.get('n_params'),\n",
    "            'val_loss': metrics.get('final_val_loss'),\n",
    "            'val_accuracy': metrics.get('final_val_accuracy'),\n",
    "            'training_time': metrics.get('training_time_sec')\n",
    "        }\n",
    "        flattened_data.append(record)\n",
    "\n",
    "    run_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    # Save individual run to CSV\n",
    "    output_path = os.path.join(CSV_FOLDER, f'run_{run_id}.csv')\n",
    "    run_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved individual run data to '{output_path}'\")\n",
    "\n",
    "    all_runs_data.append(run_df)\n",
    "\n",
    "print(\"\\n--- All individual files processed. ---\")"
   ],
   "id": "6752f4de9b14f044",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 JSON files to process...\n",
      "\n",
      "--- Processing Run 1 (transformer_architecture_scaling_results-1.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_1.csv'\n",
      "\n",
      "--- Processing Run 2 (transformer_architecture_scaling_results-2.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_2.csv'\n",
      "\n",
      "--- Processing Run 3 (transformer_architecture_scaling_results-3.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_3.csv'\n",
      "\n",
      "--- Processing Run 4 (transformer_architecture_scaling_results-4.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_4.csv'\n",
      "\n",
      "--- Processing Run 5 (transformer_architecture_scaling_results-5.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_5.csv'\n",
      "\n",
      "--- All individual files processed. ---\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T23:12:13.648008Z",
     "start_time": "2025-06-27T23:12:13.616138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if all_runs_data:\n",
    "    combined_df = pd.concat(all_runs_data, ignore_index=True)\n",
    "    combined_output_path = os.path.join(CSV_FOLDER, 'all_runs_combined.csv')\n",
    "    combined_df.to_csv(combined_output_path, index=False)\n",
    "\n",
    "    print(f\"\\nüéâ Successfully combined all runs.\")\n",
    "    print(f\"‚úÖ Master data file saved to '{combined_output_path}'\")\n",
    "    print(\"\\nCombined DataFrame preview:\")\n",
    "    display(combined_df.head())\n",
    "    print(f\"\\nTotal experiments processed: {len(combined_df)}\")\n",
    "else:\n",
    "    print(\"\\nNo data was processed.\")\n"
   ],
   "id": "235f46fff79f1da3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Successfully combined all runs.\n",
      "‚úÖ Master data file saved to 'data_csv/all_runs_combined.csv'\n",
      "\n",
      "Combined DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   run_id        experiment_key model_name size_variant     arch_type  \\\n",
       "0       1   decoder_small_n1000    decoder        small  decoder_only   \n",
       "1       1   decoder_small_n5000    decoder        small  decoder_only   \n",
       "2       1  decoder_small_n10000    decoder        small  decoder_only   \n",
       "3       1    decoder_base_n1000    decoder         base  decoder_only   \n",
       "4       1    decoder_base_n5000    decoder         base  decoder_only   \n",
       "\n",
       "   dataset_size  n_params  val_loss  val_accuracy  training_time  \n",
       "0          1000    778504  8.551140           0.0       1.873749  \n",
       "1          5000    778504  7.951559           0.0       4.987655  \n",
       "2         10000    778504  7.622734           0.0       7.977101  \n",
       "3          1000   2343304  8.500344           0.0       1.692486  \n",
       "4          5000   2343304  7.773940           0.0       7.706840  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_key</th>\n",
       "      <th>model_name</th>\n",
       "      <th>size_variant</th>\n",
       "      <th>arch_type</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>n_params</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>decoder_small_n1000</td>\n",
       "      <td>decoder</td>\n",
       "      <td>small</td>\n",
       "      <td>decoder_only</td>\n",
       "      <td>1000</td>\n",
       "      <td>778504</td>\n",
       "      <td>8.551140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.873749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>decoder_small_n5000</td>\n",
       "      <td>decoder</td>\n",
       "      <td>small</td>\n",
       "      <td>decoder_only</td>\n",
       "      <td>5000</td>\n",
       "      <td>778504</td>\n",
       "      <td>7.951559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.987655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>decoder_small_n10000</td>\n",
       "      <td>decoder</td>\n",
       "      <td>small</td>\n",
       "      <td>decoder_only</td>\n",
       "      <td>10000</td>\n",
       "      <td>778504</td>\n",
       "      <td>7.622734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.977101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>decoder_base_n1000</td>\n",
       "      <td>decoder</td>\n",
       "      <td>base</td>\n",
       "      <td>decoder_only</td>\n",
       "      <td>1000</td>\n",
       "      <td>2343304</td>\n",
       "      <td>8.500344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.692486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>decoder_base_n5000</td>\n",
       "      <td>decoder</td>\n",
       "      <td>base</td>\n",
       "      <td>decoder_only</td>\n",
       "      <td>5000</td>\n",
       "      <td>2343304</td>\n",
       "      <td>7.773940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.706840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total experiments processed: 90\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
