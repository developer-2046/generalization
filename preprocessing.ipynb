{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:21:56.359387Z",
     "start_time": "2025-06-26T04:21:56.353231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the paths for your data folders.\n",
    "# This script assumes it's running from the root of your project folder.\n",
    "JSON_FOLDER = 'data_json'\n",
    "CSV_FOLDER = 'data_csv'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"Reading from: '{JSON_FOLDER}'\")\n",
    "print(f\"Will save to: '{CSV_FOLDER}'\")"
   ],
   "id": "a2b1ab02f271a841",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: 'data_json'\n",
      "Will save to: 'data_csv'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:22:00.495496Z",
     "start_time": "2025-06-26T04:22:00.464084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_runs_data = []\n",
    "json_files = sorted(glob(os.path.join(JSON_FOLDER, 'gpu_scaling_results-*.json')))\n",
    "\n",
    "if not json_files:\n",
    "    print(\"‚ùå ERROR: No JSON files found in the 'data_json' folder.\")\n",
    "    print(\"Please make sure your result files are named 'gpu_scaling_results-n.json' and are in the correct directory.\")\n",
    "else:\n",
    "    print(f\"Found {len(json_files)} JSON files to process...\")\n",
    "\n",
    "for i, file_path in enumerate(json_files):\n",
    "    run_id = i + 1\n",
    "    print(f\"\\n--- Processing Run {run_id} ({os.path.basename(file_path)}) ---\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Flatten the nested JSON structure into a list of records\n",
    "    flattened_data = []\n",
    "    for ds_size, models in data.items():\n",
    "        for model_name, metrics in models.items():\n",
    "            record = {\n",
    "                'run_id': run_id,\n",
    "                'dataset_size': int(ds_size),\n",
    "                'model_name': model_name,\n",
    "                'arch_type': metrics.get('arch_type'),\n",
    "                'n_params': metrics.get('n_params'),\n",
    "                'train_loss': metrics.get('train_loss'),\n",
    "                'val_loss': metrics.get('val_loss'),\n",
    "                'gen_gap': metrics.get('gen_gap'),\n",
    "                'training_time': metrics.get('training_time')\n",
    "            }\n",
    "            flattened_data.append(record)\n",
    "\n",
    "    # Create a DataFrame for the current run\n",
    "    run_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    # Save the individual run to its own CSV\n",
    "    output_filename = f'run_{run_id}.csv'\n",
    "    output_path = os.path.join(CSV_FOLDER, output_filename)\n",
    "    run_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved individual run data to '{output_path}'\")\n",
    "\n",
    "    # Append the DataFrame to our master list\n",
    "    all_runs_data.append(run_df)\n",
    "\n",
    "print(\"\\n--- All individual files processed. ---\")"
   ],
   "id": "6752f4de9b14f044",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 JSON files to process...\n",
      "\n",
      "--- Processing Run 1 (gpu_scaling_results-1.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_1.csv'\n",
      "\n",
      "--- Processing Run 2 (gpu_scaling_results-2.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_2.csv'\n",
      "\n",
      "--- Processing Run 3 (gpu_scaling_results-3.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_3.csv'\n",
      "\n",
      "--- Processing Run 4 (gpu_scaling_results-4.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_4.csv'\n",
      "\n",
      "--- Processing Run 5 (gpu_scaling_results-5.json) ---\n",
      "‚úÖ Saved individual run data to 'data_csv/run_5.csv'\n",
      "\n",
      "--- All individual files processed. ---\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T04:22:06.619560Z",
     "start_time": "2025-06-26T04:22:06.582947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if all_runs_data:\n",
    "    # Concatenate all individual run DataFrames into one master DataFrame\n",
    "    combined_df = pd.concat(all_runs_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame\n",
    "    combined_output_path = os.path.join(CSV_FOLDER, 'all_runs_combined.csv')\n",
    "    combined_df.to_csv(combined_output_path, index=False)\n",
    "\n",
    "    print(f\"\\nüéâ Successfully combined all runs into a single file.\")\n",
    "    print(f\"‚úÖ Master data file saved to '{combined_output_path}'\")\n",
    "    print(\"\\nCombined DataFrame preview:\")\n",
    "    display(combined_df.head())\n",
    "    print(f\"\\nTotal experiments processed: {len(combined_df)}\")\n",
    "else:\n",
    "    print(\"\\nNo data was processed. Skipping combination step.\")"
   ],
   "id": "235f46fff79f1da3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Successfully combined all runs into a single file.\n",
      "‚úÖ Master data file saved to 'data_csv/all_runs_combined.csv'\n",
      "\n",
      "Combined DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   run_id  dataset_size         model_name    arch_type  n_params  train_loss  \\\n",
       "0       1           400   transformer_nano  transformer   3243968   10.391734   \n",
       "1       1           400  transformer_micro  transformer   6637056   10.010585   \n",
       "2       1           400          lstm_nano         lstm   3283601   10.767841   \n",
       "3       1           400         lstm_micro         lstm   6616273   10.698589   \n",
       "4       1           400           gru_nano          gru   3279377   10.734201   \n",
       "\n",
       "    val_loss   gen_gap  training_time  \n",
       "0  10.584248  0.192514       0.879869  \n",
       "1  10.341223  0.330638       0.959431  \n",
       "2  10.776723  0.008882       0.918976  \n",
       "3  10.704955  0.006366       1.014123  \n",
       "4  10.772248  0.038048       0.941737  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>arch_type</th>\n",
       "      <th>n_params</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>gen_gap</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>transformer_nano</td>\n",
       "      <td>transformer</td>\n",
       "      <td>3243968</td>\n",
       "      <td>10.391734</td>\n",
       "      <td>10.584248</td>\n",
       "      <td>0.192514</td>\n",
       "      <td>0.879869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>transformer_micro</td>\n",
       "      <td>transformer</td>\n",
       "      <td>6637056</td>\n",
       "      <td>10.010585</td>\n",
       "      <td>10.341223</td>\n",
       "      <td>0.330638</td>\n",
       "      <td>0.959431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>lstm_nano</td>\n",
       "      <td>lstm</td>\n",
       "      <td>3283601</td>\n",
       "      <td>10.767841</td>\n",
       "      <td>10.776723</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.918976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>lstm_micro</td>\n",
       "      <td>lstm</td>\n",
       "      <td>6616273</td>\n",
       "      <td>10.698589</td>\n",
       "      <td>10.704955</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>1.014123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>gru_nano</td>\n",
       "      <td>gru</td>\n",
       "      <td>3279377</td>\n",
       "      <td>10.734201</td>\n",
       "      <td>10.772248</td>\n",
       "      <td>0.038048</td>\n",
       "      <td>0.941737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total experiments processed: 160\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
